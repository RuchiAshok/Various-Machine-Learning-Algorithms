# -*- coding: utf-8 -*-
"""NeuralNetwork_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dRCT2HWCRDoWkYnqu3_JG-gGiT4tp_Bf

**Importing Libraries**
"""

import torch
import torch.nn as nn
import torch.optim as optim
import pandas as pd
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import StandardScaler    
from sklearn.model_selection import train_test_split

"""**Importing Dataset**"""

data = pd.read_csv("diabetes.csv")
data.head()

"""**Seperating input feature and target labels**"""

#Last column "Outcome" is the target label
Y = data.iloc[:, -1]   

#Input Feature Labels
X = data.iloc[:, 0:-1]

"""**Train & Test Split (70:30)**"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=70)

"""**Standardising the data of feature columns between 0 to 1**"""

Y_train = Y_train.values
Y_test = Y_test.values

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

X_train = torch.FloatTensor(X_train)
Y_train =  torch.FloatTensor(Y_train)
X_test = torch.FloatTensor(X_test)

"""**Train Data**"""

class TrainData(Dataset):
    
    def __init__(self, X, Y):
        self.Y = Y
        self.X = X
        
    def __getitem__(self, i):
        return self.X[i], self.Y[i]
        
    def __len__ (self):
        return len(self.X)

"""**Test Data**"""

class TestData(Dataset):
    
    def __init__(self, X):
        self.X = X
        
    def __getitem__(self, i):
        return self.X[i]
        
    def __len__ (self):
        return len(self.X)

train_data = TrainData(X_train,Y_train)
test_data = TestData(X_test)
train_loader = DataLoader(dataset=train_data, batch_size=70, shuffle=True)
test_loader = DataLoader(dataset=test_data, batch_size=1)

"""**Creating Neural Network for Classification**"""

class NeuralNetwork(nn.Module):
    def __init__(self):
        super(NeuralNetwork, self).__init__()

        '''
        Number of input features =  8
        Total Hidden Layers used =1, 2, 3
        Activation Functions used = Relu, Sigmoid, Tanh

        '''
        self.layer1 = nn.Linear(8, 64) 
        self.layer2 = nn.Linear(64, 12)
        self.layer3 = nn.Linear(12, 64)
        self.final_layer = nn.Linear(64, 1) 
        
        self.relu = nn.ReLU()
        #self.sigmoid = nn.Sigmoid()
        #self.tanh = nn.Tanh()

        self.dropout = nn.Dropout(p=0.1)
        self.b_norm1 = nn.BatchNorm1d(64)
        self.b_norm2 = nn.BatchNorm1d(12)
        self.b_norm3 = nn.BatchNorm1d(64)
        
    def forward(self, inputs):
        x = self.relu(self.layer1(inputs))
        #x = self.sigmoid(self.layer1(inputs))
        #x = self.tanh(self.layer1(inputs))
        x = self.b_norm1(x)
  
        x = self.relu(self.layer2(x))
        #x = self.sigmoid(self.layer2(x))
        #x = self.tanh(self.layer2(x))
        x = self.b_norm2(x)

        x = self.relu(self.layer3(x))
        #x = self.sigmoid(self.layer3(x))
        #x = self.tanh(self.layer3(x))
        x = self.b_norm3(x)

        x = self.dropout(x)
        x = self.final_layer(x)
        
        return x

model = NeuralNetwork()
model.to(device)
print(model)

loss = nn.BCEWithLogitsLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

"""**Defining Function to calculate accuracy**"""

def accuracy(Y_pred, Y_test):
    yPred = torch.round(torch.sigmoid(Y_pred))
    output = (yPred == Y_test).sum().float()
    a = output/Y_test.shape[0]
    a = torch.round(a * 100)
    return a

"""**Training the model**"""

model.train()
for i in range(1, 50):
    epoch_loss = 0
    epoch_acc = 0
    for X_batch, y_batch in train_loader:
        X_batch, y_batch = X_batch.to(device), y_batch.to(device)
        optimizer.zero_grad()
        
        y_pred = model(X_batch)
        
        loss = model_loss(y_pred, y_batch.unsqueeze(1))
        acc = accuracy(y_pred, y_batch.unsqueeze(1))
        
        loss.backward()
        optimizer.step()
        
        epoch_loss += loss.item()
        epoch_acc += acc.item()
        
    print(f'Epoch {i+0:03}: | Loss: {epoch_loss/len(train_loader):.4f} | Acc: {epoch_acc/len(train_loader):.3f}')